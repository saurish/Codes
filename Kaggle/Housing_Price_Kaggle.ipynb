{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np                # linear algebra\n",
    "import pandas as pd               # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model    import SGDRegressor\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.linear_model    import ElasticNet\n",
    "from sklearn.linear_model    import BayesianRidge\n",
    "from sklearn.linear_model    import Lasso\n",
    "from sklearn.neural_network  import MLPRegressor\n",
    "from sklearn.ensemble        import GradientBoostingRegressor\n",
    "from sklearn.ensemble        import VotingRegressor\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.preprocessing   import PolynomialFeatures\n",
    "from sklearn.preprocessing   import Imputer\n",
    "from sklearn                 import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics         import mean_absolute_error\n",
    "from xgboost                 import XGBRegressor\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot     as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def modelAccuracyOnTrainingData(x_train, y_train, model):\n",
    "    y_predict = model.predict(x_train)\n",
    "    \n",
    "    #for i in range(0, len(y_train)):\n",
    "    #    print(str(y_train[i]) + \" \" + str(y_predict[i]))\n",
    "    \n",
    "    return mean_absolute_error(y_train, y_predict) \n",
    "\n",
    "def computeKFoldCrossValidationScore(model, x_train, y_train, K, comment):\n",
    "    \n",
    "    scores = cross_val_score(model, x_train, y_train, cv=K)\n",
    "    print(\"Cross-Validation Score(\" + comment + \"): \")\n",
    "    print(scores)\n",
    "    print(\"Cross-Validation Accuracy(\" + comment + \"):\")\n",
    "    print (\"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Regressor Mean Absolute Error on Training Data: 9165.93482391279\n",
      "Cross-Validation Score(GB Regressor): \n",
      "[0.89853514 0.84743567 0.8926072  0.90853114 0.88068371]\n",
      "Cross-Validation Accuracy(GB Regressor):\n",
      "0.89 (+/- 0.04)\n",
      "[12:07:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB Regressor Mean Absolute Error on Training Data: 7753.905795162671\n",
      "[12:07:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:08:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Cross-Validation Score(XGB Regressor): \n",
      "[0.9225105  0.83783023 0.90267499 0.91473808 0.88908022]\n",
      "Cross-Validation Accuracy(XGB Regressor):\n",
      "0.89 (+/- 0.06)\n",
      "RF Regressor Mean Absolute Error on Training Data: 14588.249414972543\n",
      "Cross-Validation Score(RF Regressor): \n",
      "[0.8495295  0.83355811 0.85891236 0.8554533  0.79927979]\n",
      "Cross-Validation Accuracy(RF Regressor):\n",
      "0.84 (+/- 0.04)\n",
      "        Id      SalePrice\n",
      "0     1461  127439.742188\n",
      "1     1462  163052.078125\n",
      "2     1463  186650.765625\n",
      "3     1464  196859.703125\n",
      "4     1465  192786.968750\n",
      "...    ...            ...\n",
      "1454  2915   81889.226562\n",
      "1455  2916   82291.742188\n",
      "1456  2917  175641.578125\n",
      "1457  2918  124890.953125\n",
      "1458  2919  219678.015625\n",
      "\n",
      "[1459 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "'''\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "''' \n",
    "\n",
    "doGridSearch = False # do grid search once and save the results for future use\n",
    "\n",
    "X_train = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\n",
    "X_test  = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\n",
    "\n",
    "y_train = X_train.iloc[:, -1]\n",
    "X_train = X_train.iloc[:, :-1] # training set after removing last column\n",
    "\n",
    "# Get a summary of the traning data\n",
    "#print (\"Summary of training data : \")\n",
    "#print (X_train.info())\n",
    "\n",
    "# Training data \n",
    "#print (\"Training data overview\")\n",
    "#print (X_train.head())\n",
    "\n",
    "# plot histogram for numerical values\n",
    "#X_train.hist(bins=50, figsize=(40, 30))\n",
    "#plt.show()\n",
    "\n",
    "##################################################### DATA PREPOROCESSING ######################################################\n",
    "\n",
    "# do one-hot-encoding to handle categorical values\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_test_encoded  = pd.get_dummies(X_test)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = Imputer(strategy=\"mean\")\n",
    "imputer.fit (X_train_encoded)\n",
    "X_train_encoded_tr = pd.DataFrame( imputer.transform(X_train_encoded), columns = X_train_encoded.columns)\n",
    "\n",
    "imputer.fit (X_test_encoded)\n",
    "X_test_encoded_tr  = pd.DataFrame( imputer.transform(X_test_encoded), columns = X_test_encoded.columns)\n",
    "\n",
    "#print(imputer.statistics_)\n",
    "#print(X_train_encoded.median().values)\n",
    "\n",
    "# statistical analysis of traning set\n",
    "#print(X_train_encoded.describe())\n",
    "\n",
    "# normalize data for better performance of GD\n",
    "#X_train_encoded_tr_norm = (X_train_encoded_tr - X_train_encoded_tr.mean()) / X_train_encoded_tr.std()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_encoded_tr)\n",
    "X_train_encoded_tr_norm =  pd.DataFrame(scaler.transform(X_train_encoded_tr), columns = X_train_encoded.columns)\n",
    "\n",
    "train_data_headers = list(X_train_encoded_tr_norm.columns)\n",
    "test_data_headers  = list(X_test_encoded_tr.columns)\n",
    "##################################################################################################################################\n",
    "\n",
    "######################################################## TRAINING ################################################################\n",
    "\n",
    "'''\n",
    "# [1]. apply linear regression\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train_encoded_tr_norm, y_train) #training the algorithm\n",
    "#print(regressor.score(X_train_encoded_tr, y_train))\n",
    "#print(regressor.coef_)\n",
    "\n",
    "#print(X_test_encoded_tr.head().values)\n",
    "\n",
    "print(\"Linear Regression Mean Absolute Error on Training Data: \" + str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, regressor)))\n",
    "\n",
    "## computing cross-validation score of our model -- linear regression\n",
    "computeKFoldCrossValidationScore(regressor, X_train_encoded_tr_norm, y_train, 5, \"Linear Regression\")\n",
    "\n",
    "# [2]. apply regularized linear regression\n",
    "reg_regressor = Lasso(normalize=True)  \n",
    "reg_regressor.fit(X_train_encoded_tr_norm, y_train) #training the algorithm\n",
    "\n",
    "print(\"Linear Regression with Reg Mean Absolute Error on Training Data: \" + str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, reg_regressor)))\n",
    "\n",
    "## computing cross-validation score of our model -- linear regression\n",
    "computeKFoldCrossValidationScore(reg_regressor, X_train_encoded_tr_norm, y_train, 5, \"Regularized Lin Reg\")\n",
    "'''\n",
    "\n",
    "# [3]. Gradient Boosting Regressor\n",
    "\n",
    "gb_regressor = None\n",
    "if doGridSearch: # perform grid search to find the best parameter set\n",
    "    params = [ {'n_estimators': [300, 400, 500, 600, 700], 'max_depth': [4,5, 6], \n",
    "            'min_samples_split': [2,3], 'learning_rate': [ 0.01], 'loss': ['ls']} ]\n",
    "    \n",
    "    gb_regressor       = GradientBoostingRegressor()\n",
    "    gb_grid_search     = GridSearchCV(gb_regressor, params, cv = 5, scoring='neg_mean_squared_error')\n",
    "    gb_grid_search.fit(X_train_encoded_tr_norm, y_train)\n",
    "    \n",
    "    print(\"Grid Search Best Parameters(GB Regressor): \")\n",
    "    print(gb_grid_search.best_params_)\n",
    "    \n",
    "    cvres = gb_grid_search.cv_results_\n",
    "    with open(\"GB_Regressor_GridSearch.txt\", \"w+\") as outFile:\n",
    "        for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "            outFile.write(str(np.sqrt(-mean_score)) +  str(params))\n",
    "        \n",
    "else:\n",
    "    params       = {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    gb_regressor = GradientBoostingRegressor(**params)\n",
    "    gb_regressor.fit(X_train_encoded_tr_norm, y_train)\n",
    "    print(\"GB Regressor Mean Absolute Error on Training Data: \" + \n",
    "           str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, gb_regressor)))\n",
    "    \n",
    "    ## computing cross-validation score of our model -- \n",
    "    computeKFoldCrossValidationScore(gb_regressor, X_train_encoded_tr_norm, y_train, 5, \"GB Regressor\")\n",
    "\n",
    "# [4]. XGBoost\n",
    "\n",
    "xgb_regressor = None\n",
    "if doGridSearch: # perform grid search to find the best parameter set\n",
    "    \n",
    "    params = [ {'objective' : ['reg:linear'],'colsample_bytree' : [0.3], 'learning_rate' : [0.01, 0.05, 0.1],\n",
    "                'max_depth' : [3, 4 ,5, 6], 'alpha' : [10],  'n_estimators' : [100, 200, 300, 400, 500,600] }]\n",
    "    \n",
    "    xgb_regressor       = XGBRegressor()\n",
    "    xgb_grid_search     = GridSearchCV(xgb_regressor, params, cv = 5, scoring='neg_mean_squared_error')\n",
    "    xgb_grid_search.fit(X_train_encoded_tr_norm, y_train)\n",
    "    \n",
    "    print(\"Grid Search Best Parameters(XGB Regressor): \")\n",
    "    print(xgb_grid_search.best_params_)\n",
    "    \n",
    "    cvres = xgb_grid_search.cv_results_\n",
    "    with open(\"XGB_Regressor_GridSearch.txt\", \"w+\") as outFile:\n",
    "        for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "            outFile.write(str(np.sqrt(-mean_score)) + str(params))\n",
    "        \n",
    "else:\n",
    "    xgb_regressor = XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3,  learning_rate = 0.05, max_depth = 3, alpha = 10, \n",
    "                                 n_estimators = 600)\n",
    "    xgb_regressor.fit(X_train_encoded_tr_norm, y_train)\n",
    "    print(\"XGB Regressor Mean Absolute Error on Training Data: \" + \n",
    "           str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, xgb_regressor)))\n",
    "    \n",
    "    ## computing cross-validation score of our model -- \n",
    "    computeKFoldCrossValidationScore(xgb_regressor, X_train_encoded_tr_norm, y_train, 5, \"XGB Regressor\")\n",
    "\n",
    "# [5]. RandomForestRegressor\n",
    "\n",
    "rf_regressor = None\n",
    "if doGridSearch: # perform grid search to find the best parameter set\n",
    "    \n",
    "    params = [ {'max_depth': [3, 4, 5, 6], 'random_state' : [0], 'n_estimators' : [100, 200, 300, 400, 500, 600] }]\n",
    "    \n",
    "    rf_regressor       = RandomForestRegressor()\n",
    "    rf_grid_search     = GridSearchCV(rf_regressor, params, cv = 5, scoring='neg_mean_squared_error')\n",
    "    rf_grid_search.fit(X_train_encoded_tr_norm, y_train)\n",
    "    \n",
    "    print(\"Grid Search Best Parameters(RF Regressor): \")\n",
    "    print(rf_grid_search.best_params_)\n",
    "    \n",
    "    cvres = rf_grid_search.cv_results_\n",
    "    with open(\"RF_Regressor_GridSearch.txt\", \"w+\") as outFile:\n",
    "        for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "            outFile.write(str(np.sqrt(-mean_score)) + str(params))\n",
    "else:\n",
    "    rf_regressor = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=300)\n",
    "    rf_regressor.fit(X_train_encoded_tr_norm, y_train)  \n",
    "    print(\"RF Regressor Mean Absolute Error on Training Data: \" + str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, rf_regressor)))\n",
    "    ## computing cross-validation score of our model -- \n",
    "    computeKFoldCrossValidationScore(rf_regressor, X_train_encoded_tr_norm, y_train, 5, \"RF Regressor\")\n",
    "\n",
    "if doGridSearch:\n",
    "    sys.exit(0)\n",
    "\n",
    "#################################################################################################################################\n",
    "\n",
    "######################################################## PREDICTION #############################################################\n",
    "# augment missing columns to test dataset\n",
    "index = 0\n",
    "for col in X_train_encoded_tr_norm.columns:\n",
    "    if col not in X_test_encoded_tr.columns:\n",
    "        X_test_encoded_tr.insert(index, col, [0.0] * X_test_encoded.shape[0], True)\n",
    "    index += 1\n",
    "    \n",
    "# test code\n",
    "for i in range(len(X_train_encoded_tr_norm.columns)):\n",
    "    assert  X_train_encoded_tr_norm.columns[i] == X_test_encoded_tr.columns[i]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_test_encoded_tr)\n",
    "X_test_encoded_tr_norm =  pd.DataFrame(scaler.transform(X_test_encoded_tr), columns = X_test_encoded_tr.columns)\n",
    "\n",
    "# NOTE : Voting classifier didn't give good result.\n",
    "#vr = VotingRegressor([('gb', gb_regressor), ('xgb', xgb_regressor)])\n",
    "#predictions = vr.fit(X_train_encoded_tr_norm, y_train).predict(X_test_encoded_tr_norm) #\n",
    "predictions = xgb_regressor.predict(X_test_encoded_tr_norm)\n",
    "#print(\"Voting Regressor Mean Absolute Error on Training Data: \" + str(modelAccuracyOnTrainingData(X_train_encoded_tr_norm, y_train, vr)))\n",
    "#computeKFoldCrossValidationScore(vr, X_train_encoded_tr_norm, y_train, 5, \"Voting Regressor\")\n",
    "\n",
    "outputDF = pd.DataFrame({ 'Id' : list(X_test_encoded_tr['Id']), 'SalePrice' : predictions})\n",
    "outputDF = outputDF.astype({'Id': 'int64'})\n",
    "print(outputDF)\n",
    "\n",
    "\n",
    "# dump output to CSV\n",
    "outputDF.to_csv(\"price_submission.csv\", index=False)\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
